{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "savedmode_name=\"model_seed42_score0.991.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cp: cannot stat '/kaggle/input/utility/*': No such file or directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "# %pip install --force-reinstall /kaggle/input/unidecode/Unidecode-1.3.8-py3-none-any.whl\n",
    "%cp /kaggle/input/utility/* ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/z1933/workplace/machinelearning/PII-Data-Detection//modelsave/model_seed42_score0.991.pth'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO:change path\n",
    "from cfg import *\n",
    "from util import *\n",
    "from model1 import NLPModel\n",
    "import gc\n",
    "\n",
    "# Config.data_path='/kaggle/input/pii-detection-removal-from-educational-data/'\n",
    "# Config.modelsavepath='/kaggle/input/deberbase0213'\n",
    "tokenizer_path=Config.modelsavepath\n",
    "modelpath=Config.modelsavepath+savedmode_name\n",
    "modelpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/z1933/workplace/machinelearning/PII-Data-Detection//modelsave/'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Config.modelsavepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from itertools import chain\n",
    "from transformers import AutoModelForTokenClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.load(open(Config.data_path+\"/test.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['full_text', 'document', 'tokens', 'trailing_whitespace'],\n",
       "    num_rows: 10\n",
       "})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = Dataset.from_dict({\n",
    "    \"full_text\": [x[\"full_text\"] for x in data],\n",
    "    \"document\": [str(x[\"document\"]) for x in data],\n",
    "    \"tokens\": [x[\"tokens\"] for x in data],\n",
    "    \"trailing_whitespace\": [x[\"trailing_whitespace\"] for x in data],\n",
    "})\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/z1933/workplace/machinelearning/PII-Data-Detection//modelsave/'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': 'B-EMAIL',\n",
       " '1': 'B-ID_NUM',\n",
       " '2': 'B-NAME_STUDENT',\n",
       " '3': 'B-PHONE_NUM',\n",
       " '4': 'B-STREET_ADDRESS',\n",
       " '5': 'B-URL_PERSONAL',\n",
       " '6': 'B-USERNAME',\n",
       " '7': 'I-ID_NUM',\n",
       " '8': 'I-NAME_STUDENT',\n",
       " '9': 'I-PHONE_NUM',\n",
       " '10': 'I-STREET_ADDRESS',\n",
       " '11': 'I-URL_PERSONAL',\n",
       " '12': 'O'}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n",
    "idlabel= json.load(open(Config.modelsavepath+\"//idlabel.json\"))\n",
    "id2label=idlabel['id2label']\n",
    "label2id=idlabel['label2id']\n",
    "id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_preprocesss(example,tokenizer,label2id):\n",
    "    # rebuild text from tokens\n",
    "\n",
    "    example['token_map']=[]\n",
    "    example['berttokenids']=[]\n",
    "    example['berttokenmask']=[]\n",
    "    example['berttokentoken_type_ids']=[]\n",
    "    example['offset_mapping']=[]\n",
    "\n",
    "    tokens_split_list=[]\n",
    "    trailing_whitespace_split_list=[]\n",
    "\n",
    "    right_idx=0\n",
    "    for i in range(0,len(example['tokens'])):\n",
    "        if example['tokens'][i] == '\\n\\n':\n",
    "            tokens_split_list.append(example['tokens'][right_idx:i+1])\n",
    "            trailing_whitespace_split_list.append(example['trailing_whitespace'][right_idx:i+1])\n",
    "            right_idx=i+1\n",
    "\n",
    "    if  len(tokens_split_list)==0:\n",
    "        tokens_split_list.append( example['tokens'])\n",
    "        trailing_whitespace_split_list.append( example['trailing_whitespace'])\n",
    "\n",
    "    idx=0\n",
    "    for tokens_list,trailing_whitespace_list in zip(\n",
    "        tokens_split_list,trailing_whitespace_split_list):\n",
    "\n",
    "        text = []\n",
    "        token_map = []\n",
    "\n",
    "        for t,  ws in zip(\n",
    "            tokens_list, trailing_whitespace_list\n",
    "        ):\n",
    "            text.append(t)\n",
    "            token_map.extend([idx]*len(t))\n",
    "\n",
    "            if ws:\n",
    "                text.append(\" \")\n",
    "                token_map.append(-1)\n",
    "            idx += 1\n",
    "        # actual tokenization\n",
    "        tokenized = tokenizer(\"\".join(text), return_offsets_mapping=True)\n",
    "\n",
    "        example['berttokenids'].append(tokenized['input_ids'])\n",
    "        example['berttokenmask'].append(tokenized['attention_mask'])\n",
    "        example['berttokentoken_type_ids'].append(tokenized['token_type_ids'])\n",
    "        example['offset_mapping'].append(tokenized['offset_mapping'])\n",
    "        example['token_map'].append(token_map)\n",
    "        \n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f02138d36b6c4c78b77423a4a7320ff5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "prepocessing data:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preprocesssed_ds=ds.map(inference_preprocesss, fn_kwargs={'tokenizer':tokenizer,'label2id':label2id},num_proc=1,desc=\"prepocessing data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean     30.692015\n",
      "max     541.000000\n",
      "std      55.285935\n",
      "min       3.000000\n",
      "Name: berttokenids, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>document</th>\n",
       "      <th>tokens</th>\n",
       "      <th>trailing_whitespace</th>\n",
       "      <th>berttokenids</th>\n",
       "      <th>berttokenmask</th>\n",
       "      <th>berttokentoken_type_ids</th>\n",
       "      <th>token_map</th>\n",
       "      <th>offset_mapping</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Design Thinking for innovation reflexion-Avril...</td>\n",
       "      <td>7</td>\n",
       "      <td>[Design, Thinking, for, innovation, reflexion,...</td>\n",
       "      <td>[True, True, True, True, False, False, True, F...</td>\n",
       "      <td>[1, 2169, 12103, 270, 3513, 28310, 4593, 271, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, -1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n",
       "      <td>[[0, 0], [0, 6], [6, 15], [15, 19], [19, 30], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Design Thinking for innovation reflexion-Avril...</td>\n",
       "      <td>7</td>\n",
       "      <td>[Design, Thinking, for, innovation, reflexion,...</td>\n",
       "      <td>[True, True, True, True, False, False, True, F...</td>\n",
       "      <td>[1, 6738, 429, 1857, 2]</td>\n",
       "      <td>[1, 1, 1, 1, 1]</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "      <td>[12, 12, 12, 12, 12, 12, 12, 12, 12, -1, 13, -...</td>\n",
       "      <td>[[0, 0], [0, 9], [9, 11], [11, 21], [0, 0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Design Thinking for innovation reflexion-Avril...</td>\n",
       "      <td>7</td>\n",
       "      <td>[Design, Thinking, for, innovation, reflexion,...</td>\n",
       "      <td>[True, True, True, True, False, False, True, F...</td>\n",
       "      <td>[1, 279, 1637, 273, 380, 264, 408, 305, 6998, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[16, 16, 16, -1, 17, 17, 17, 17, -1, 18, -1, 1...</td>\n",
       "      <td>[[0, 0], [0, 3], [3, 8], [8, 10], [10, 14], [1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Design Thinking for innovation reflexion-Avril...</td>\n",
       "      <td>7</td>\n",
       "      <td>[Design, Thinking, for, innovation, reflexion,...</td>\n",
       "      <td>[True, True, True, True, False, False, True, F...</td>\n",
       "      <td>[1, 458, 1444, 269, 266, 791, 2269, 302, 1663,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[40, 40, 40, 40, -1, 41, 41, 41, 41, 41, 41, 4...</td>\n",
       "      <td>[[0, 0], [0, 4], [4, 12], [12, 15], [15, 17], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Design Thinking for innovation reflexion-Avril...</td>\n",
       "      <td>7</td>\n",
       "      <td>[Design, Thinking, for, innovation, reflexion,...</td>\n",
       "      <td>[True, True, True, True, False, False, True, F...</td>\n",
       "      <td>[1, 329, 1637, 303, 386, 5228, 294, 2]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[110, 110, 110, 110, -1, 111, 111, 111, 111, -...</td>\n",
       "      <td>[[0, 0], [0, 4], [4, 9], [9, 13], [13, 18], [1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>Gandhi Institute of Technology and Management ...</td>\n",
       "      <td>123</td>\n",
       "      <td>[Gandhi, Institute, of, Technology, and, Manag...</td>\n",
       "      <td>[True, True, True, True, True, True, False, Tr...</td>\n",
       "      <td>[1, 287, 13229, 294, 320, 320, 63456, 12630, 4...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1590, 1591, 1591, 1591, 1591, 1591, 1591, 159...</td>\n",
       "      <td>[[0, 0], [0, 1], [1, 6], [6, 7], [7, 8], [8, 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>Gandhi Institute of Technology and Management ...</td>\n",
       "      <td>123</td>\n",
       "      <td>[Gandhi, Institute, of, Technology, and, Manag...</td>\n",
       "      <td>[True, True, True, True, True, True, False, Tr...</td>\n",
       "      <td>[1, 453, 260, 16015, 12626, 851, 260, 56568, 8...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1600, 1601, -1, 1602, 1602, 1602, 1602, 1602,...</td>\n",
       "      <td>[[0, 0], [0, 1], [1, 2], [2, 8], [8, 11], [11,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>Gandhi Institute of Technology and Management ...</td>\n",
       "      <td>123</td>\n",
       "      <td>[Gandhi, Institute, of, Technology, and, Manag...</td>\n",
       "      <td>[True, True, True, True, True, True, False, Tr...</td>\n",
       "      <td>[1, 21584, 358, 261, 851, 260, 2316, 474, 5133...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1621, 1621, 1621, 1621, 1622, -1, 1623, 1623,...</td>\n",
       "      <td>[[0, 0], [0, 3], [3, 4], [4, 5], [5, 7], [7, 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>Gandhi Institute of Technology and Management ...</td>\n",
       "      <td>123</td>\n",
       "      <td>[Gandhi, Institute, of, Technology, and, Manag...</td>\n",
       "      <td>[True, True, True, True, True, True, False, Tr...</td>\n",
       "      <td>[1, 456, 260, 96307, 829, 260, 261, 18030, 114...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1651, 1652, -1, 1653, 1653, 1653, 1653, -1, 1...</td>\n",
       "      <td>[[0, 0], [0, 1], [1, 2], [2, 7], [7, 9], [9, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>Gandhi Institute of Technology and Management ...</td>\n",
       "      <td>123</td>\n",
       "      <td>[Gandhi, Institute, of, Technology, and, Manag...</td>\n",
       "      <td>[True, True, True, True, True, True, False, Tr...</td>\n",
       "      <td>[1, 1519, 263, 353, 7715, 840, 320, 13156, 265...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1670, 1670, 1670, 1670, 1670, 1670, 1670, 167...</td>\n",
       "      <td>[[0, 0], [0, 8], [8, 12], [12, 16], [16, 25], ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>263 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             full_text document  \\\n",
       "0    Design Thinking for innovation reflexion-Avril...        7   \n",
       "1    Design Thinking for innovation reflexion-Avril...        7   \n",
       "2    Design Thinking for innovation reflexion-Avril...        7   \n",
       "3    Design Thinking for innovation reflexion-Avril...        7   \n",
       "4    Design Thinking for innovation reflexion-Avril...        7   \n",
       "..                                                 ...      ...   \n",
       "258  Gandhi Institute of Technology and Management ...      123   \n",
       "259  Gandhi Institute of Technology and Management ...      123   \n",
       "260  Gandhi Institute of Technology and Management ...      123   \n",
       "261  Gandhi Institute of Technology and Management ...      123   \n",
       "262  Gandhi Institute of Technology and Management ...      123   \n",
       "\n",
       "                                                tokens  \\\n",
       "0    [Design, Thinking, for, innovation, reflexion,...   \n",
       "1    [Design, Thinking, for, innovation, reflexion,...   \n",
       "2    [Design, Thinking, for, innovation, reflexion,...   \n",
       "3    [Design, Thinking, for, innovation, reflexion,...   \n",
       "4    [Design, Thinking, for, innovation, reflexion,...   \n",
       "..                                                 ...   \n",
       "258  [Gandhi, Institute, of, Technology, and, Manag...   \n",
       "259  [Gandhi, Institute, of, Technology, and, Manag...   \n",
       "260  [Gandhi, Institute, of, Technology, and, Manag...   \n",
       "261  [Gandhi, Institute, of, Technology, and, Manag...   \n",
       "262  [Gandhi, Institute, of, Technology, and, Manag...   \n",
       "\n",
       "                                   trailing_whitespace  \\\n",
       "0    [True, True, True, True, False, False, True, F...   \n",
       "1    [True, True, True, True, False, False, True, F...   \n",
       "2    [True, True, True, True, False, False, True, F...   \n",
       "3    [True, True, True, True, False, False, True, F...   \n",
       "4    [True, True, True, True, False, False, True, F...   \n",
       "..                                                 ...   \n",
       "258  [True, True, True, True, True, True, False, Tr...   \n",
       "259  [True, True, True, True, True, True, False, Tr...   \n",
       "260  [True, True, True, True, True, True, False, Tr...   \n",
       "261  [True, True, True, True, True, True, False, Tr...   \n",
       "262  [True, True, True, True, True, True, False, Tr...   \n",
       "\n",
       "                                          berttokenids  \\\n",
       "0    [1, 2169, 12103, 270, 3513, 28310, 4593, 271, ...   \n",
       "1                              [1, 6738, 429, 1857, 2]   \n",
       "2    [1, 279, 1637, 273, 380, 264, 408, 305, 6998, ...   \n",
       "3    [1, 458, 1444, 269, 266, 791, 2269, 302, 1663,...   \n",
       "4               [1, 329, 1637, 303, 386, 5228, 294, 2]   \n",
       "..                                                 ...   \n",
       "258  [1, 287, 13229, 294, 320, 320, 63456, 12630, 4...   \n",
       "259  [1, 453, 260, 16015, 12626, 851, 260, 56568, 8...   \n",
       "260  [1, 21584, 358, 261, 851, 260, 2316, 474, 5133...   \n",
       "261  [1, 456, 260, 96307, 829, 260, 261, 18030, 114...   \n",
       "262  [1, 1519, 263, 353, 7715, 840, 320, 13156, 265...   \n",
       "\n",
       "                                         berttokenmask  \\\n",
       "0    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1                                      [1, 1, 1, 1, 1]   \n",
       "2    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "3    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "4                             [1, 1, 1, 1, 1, 1, 1, 1]   \n",
       "..                                                 ...   \n",
       "258  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "259  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "260  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "261  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "262  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "\n",
       "                               berttokentoken_type_ids  \\\n",
       "0    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1                                      [0, 0, 0, 0, 0]   \n",
       "2    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4                             [0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "..                                                 ...   \n",
       "258  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "259  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "260  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "261  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "262  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                             token_map  \\\n",
       "0    [0, 0, 0, 0, 0, 0, -1, 1, 1, 1, 1, 1, 1, 1, 1,...   \n",
       "1    [12, 12, 12, 12, 12, 12, 12, 12, 12, -1, 13, -...   \n",
       "2    [16, 16, 16, -1, 17, 17, 17, 17, -1, 18, -1, 1...   \n",
       "3    [40, 40, 40, 40, -1, 41, 41, 41, 41, 41, 41, 4...   \n",
       "4    [110, 110, 110, 110, -1, 111, 111, 111, 111, -...   \n",
       "..                                                 ...   \n",
       "258  [1590, 1591, 1591, 1591, 1591, 1591, 1591, 159...   \n",
       "259  [1600, 1601, -1, 1602, 1602, 1602, 1602, 1602,...   \n",
       "260  [1621, 1621, 1621, 1621, 1622, -1, 1623, 1623,...   \n",
       "261  [1651, 1652, -1, 1653, 1653, 1653, 1653, -1, 1...   \n",
       "262  [1670, 1670, 1670, 1670, 1670, 1670, 1670, 167...   \n",
       "\n",
       "                                        offset_mapping  \n",
       "0    [[0, 0], [0, 6], [6, 15], [15, 19], [19, 30], ...  \n",
       "1          [[0, 0], [0, 9], [9, 11], [11, 21], [0, 0]]  \n",
       "2    [[0, 0], [0, 3], [3, 8], [8, 10], [10, 14], [1...  \n",
       "3    [[0, 0], [0, 4], [4, 12], [12, 15], [15, 17], ...  \n",
       "4    [[0, 0], [0, 4], [4, 9], [9, 13], [13, 18], [1...  \n",
       "..                                                 ...  \n",
       "258  [[0, 0], [0, 1], [1, 6], [6, 7], [7, 8], [8, 9...  \n",
       "259  [[0, 0], [0, 1], [1, 2], [2, 8], [8, 11], [11,...  \n",
       "260  [[0, 0], [0, 3], [3, 4], [4, 5], [5, 7], [7, 8...  \n",
       "261  [[0, 0], [0, 1], [1, 2], [2, 7], [7, 9], [9, 1...  \n",
       "262  [[0, 0], [0, 8], [8, 12], [12, 16], [16, 25], ...  \n",
       "\n",
       "[263 rows x 9 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rebuid dataset \n",
    "tmp_pd=expanddataset(preprocesssed_ds,if_train=False)\n",
    "print(tmp_pd['berttokenids'].str.len().agg(['mean','max','std','min']))\n",
    "tmp_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['full_text', 'document', 'tokens', 'trailing_whitespace', 'berttokenids', 'berttokenmask', 'berttokentoken_type_ids', 'token_map', 'offset_mapping'],\n",
       "    num_rows: 263\n",
       "})"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_ds=Dataset.from_pandas(tmp_pd)\n",
    "full_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model=NLPModel(id2label,label2id,Config.modelsavepath,training=False).to(device)\n",
    "model.load_state_dict(torch.load(modelpath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = Collate(tokenizer=tokenizer,if_train=False)\n",
    "val_dataloader=DataLoader(full_ds,batch_size=1,pin_memory=True,collate_fn=data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 263/263 [00:03<00:00, 71.61it/s]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "allprecitions=[]\n",
    "for step,dataset in enumerate(tqdm(val_dataloader)):\n",
    "\n",
    "    with torch.no_grad():\n",
    "        ids = dataset[\"ids\"].to(device,non_blocking=True)\n",
    "        mask = dataset[\"mask\"].to(device,non_blocking=True)\n",
    "        tokentype = dataset[\"type_ids\"].to(device,non_blocking=True)\n",
    "        logit,loss = model(ids,mask,tokentype)\n",
    "        allprecitions.append(logit2truepredic(logit))\n",
    "        del ids,mask,tokentype\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplets = set()\n",
    "document, token, label, token_str = [], [], [], []\n",
    "\n",
    "for p,token_map, offsets,tokens, doc in zip(allprecitions,full_ds[\"token_map\"], full_ds['offset_mapping'],full_ds[\"tokens\"], full_ds[\"document\"]):\n",
    "\n",
    "    tmp_id=0\n",
    "    for token_pred, (start_idx, end_idx) in zip(p, offsets):\n",
    "        label_pred = id2label[str(token_pred)]\n",
    "        if start_idx + end_idx == 0: continue\n",
    "        if token_map[start_idx] == -1:\n",
    "            start_idx += 1\n",
    "\n",
    "         # ignore \"\\n\\n\"\n",
    "        while start_idx < len(token_map) and  tokens[token_map[start_idx]].isspace():\n",
    "            start_idx += 1\n",
    "\n",
    "        if start_idx >= len(token_map): break\n",
    "\n",
    "        token_id = token_map[start_idx]\n",
    "\n",
    "        # ignore \"O\" predictions and whitespace preds\n",
    "        if label_pred != \"O\" and token_id != -1:\n",
    "            triplet = (label_pred, token_id, tokens[token_id])\n",
    "\n",
    "            if triplet not in triplets:\n",
    "                document.append(doc)\n",
    "                token.append(token_id)\n",
    "                label.append(label_pred)\n",
    "                token_str.append(tokens[token_id])\n",
    "                triplets.add(triplet)\n",
    "        tmp_id+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>token</th>\n",
       "      <th>label</th>\n",
       "      <th>token_str</th>\n",
       "      <th>row_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Nathalie</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Sylla</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>482</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Nathalie</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>483</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Sylla</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>741</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Nathalie</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>742</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Sylla</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Diego</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Estrada</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>464</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Diego</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>465</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Estrada</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Gilberto</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Gamboa</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Sindy</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Samaca</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>56</td>\n",
       "      <td>12</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Nadine</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>56</td>\n",
       "      <td>13</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Born</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>86</td>\n",
       "      <td>6</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Eladio</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>86</td>\n",
       "      <td>7</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Amaya</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Silvia</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>93</td>\n",
       "      <td>1</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Villalobos</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>104</td>\n",
       "      <td>8</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Sakir</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>104</td>\n",
       "      <td>9</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Ahmad</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>112</td>\n",
       "      <td>5</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Francisco</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>112</td>\n",
       "      <td>6</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Ferreira</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>123</td>\n",
       "      <td>32</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Stefano</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>123</td>\n",
       "      <td>33</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Lovato</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   document  token           label   token_str  row_id\n",
       "0         7      9  B-NAME_STUDENT    Nathalie       0\n",
       "1         7     10  I-NAME_STUDENT       Sylla       1\n",
       "2         7    482  B-NAME_STUDENT    Nathalie       2\n",
       "3         7    483  I-NAME_STUDENT       Sylla       3\n",
       "4         7    741  B-NAME_STUDENT    Nathalie       4\n",
       "5         7    742  I-NAME_STUDENT       Sylla       5\n",
       "6        10      0  B-NAME_STUDENT       Diego       6\n",
       "7        10      1  I-NAME_STUDENT     Estrada       7\n",
       "8        10    464  B-NAME_STUDENT       Diego       8\n",
       "9        10    465  I-NAME_STUDENT     Estrada       9\n",
       "10       16      4  B-NAME_STUDENT    Gilberto      10\n",
       "11       16      5  I-NAME_STUDENT      Gamboa      11\n",
       "12       20      5  B-NAME_STUDENT       Sindy      12\n",
       "13       20      6  I-NAME_STUDENT      Samaca      13\n",
       "14       56     12  B-NAME_STUDENT      Nadine      14\n",
       "15       56     13  I-NAME_STUDENT        Born      15\n",
       "16       86      6  B-NAME_STUDENT      Eladio      16\n",
       "17       86      7  I-NAME_STUDENT       Amaya      17\n",
       "18       93      0  B-NAME_STUDENT      Silvia      18\n",
       "19       93      1  I-NAME_STUDENT  Villalobos      19\n",
       "20      104      8  B-NAME_STUDENT       Sakir      20\n",
       "21      104      9  I-NAME_STUDENT       Ahmad      21\n",
       "22      112      5  B-NAME_STUDENT   Francisco      22\n",
       "23      112      6  I-NAME_STUDENT    Ferreira      23\n",
       "24      123     32  B-NAME_STUDENT     Stefano      24\n",
       "25      123     33  I-NAME_STUDENT      Lovato      25"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"document\": document,\n",
    "    \"token\": token,\n",
    "    \"label\": label,\n",
    "    \"token_str\": token_str\n",
    "})\n",
    "df[\"row_id\"] = list(range(len(df)))\n",
    "display(df.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"row_id\", \"document\", \"token\", \"label\"]].to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
